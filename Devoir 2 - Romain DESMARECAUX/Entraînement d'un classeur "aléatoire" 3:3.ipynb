{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6ad0f52",
   "metadata": {},
   "source": [
    "# \"Classeur aléatoire\"\n",
    "\n",
    "Pour teste le \"classeur aléatoire\" nous allons denouveau faire la même chose que pour les classeurs précedent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc05f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des données: Customer.csv\n",
    "import pandas as pd # importation du module pandas\n",
    "import numpy as np\n",
    "#Récupération des données avec la fonction read_csv()\n",
    "customers = pd.read_csv(\"Data_traites.csv\") \n",
    "customers_test = pd.read_csv(\"Test_traites.csv\")\n",
    "country_population = pd.read_csv(\"CountryPopulation.csv\")\n",
    "country_PIB = pd.read_csv(\"CountryGDP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c098dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binaire(data):\n",
    "    newcolonne = []\n",
    "    for valeur in data[\"gender\"]:\n",
    "        if(valeur == 'Masc'):\n",
    "            valeur = '0'\n",
    "        else:\n",
    "            valeur = '1'\n",
    "        newcolonne.append(pd.to_numeric(valeur, errors = 'coerce'))\n",
    "    data[\"gender\"] = newcolonne\n",
    "        \n",
    "customers_copy = customers.copy()\n",
    "test_copy = customers_test.copy()\n",
    "\n",
    "to_binaire(customers_copy)\n",
    "to_binaire(test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ef9373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  pages  first_item_prize  gender  ReBuy  News_click     country  \\\n",
      "9254  36.0    6.0              10.0       0  False         3.0       Ghana   \n",
      "1561  36.0    6.0              22.0       0   True         4.0  Bangladesh   \n",
      "1670  38.0    3.0              44.0       1  False         3.0      Russia   \n",
      "6087  36.0    4.0              15.5       0  False        10.0   Argentina   \n",
      "6669  40.0    4.0              15.5       1  False         7.0       Sudan   \n",
      "...    ...    ...               ...     ...    ...         ...         ...   \n",
      "5734  48.0    7.0              44.0       0   True         6.0    Tanzania   \n",
      "5191  25.0   10.0              22.0       1  False         2.0    Colombia   \n",
      "5390  34.0    3.0              28.0       0  False         6.0       Spain   \n",
      "860   37.0    7.0              10.0       0  False         8.0      Brazil   \n",
      "7270  49.0    4.0              15.5       0   True         3.0        Iraq   \n",
      "\n",
      "     revenue  \n",
      "9254       0  \n",
      "1561       0  \n",
      "1670       1  \n",
      "6087       1  \n",
      "6669       0  \n",
      "...      ...  \n",
      "5734       2  \n",
      "5191       0  \n",
      "5390       1  \n",
      "860        1  \n",
      "7270       0  \n",
      "\n",
      "[8000 rows x 8 columns]\n",
      "       age  pages  first_item_prize  gender  ReBuy  News_click       country  \\\n",
      "6252  54.0    3.0              15.5       0  False         3.0       Algeria   \n",
      "4684  37.0    5.0              28.0       1   True         5.0  South Africa   \n",
      "1731  43.0    7.0              28.0       0   True         3.0        Russia   \n",
      "4742  33.0    5.0              28.0       1   True         4.0  South Africa   \n",
      "4521  40.0    5.0              57.0       0  False         2.0         Burma   \n",
      "...    ...    ...               ...     ...    ...         ...           ...   \n",
      "6412  42.0    5.0              42.0       0   True         5.0        Poland   \n",
      "8285  37.0    6.0              22.0       1  False         1.0  Saudi Arabia   \n",
      "7853  48.0    5.0              44.0       0   True        10.0    Uzbekistan   \n",
      "1095  36.0    8.0              57.0       0   True         6.0      Pakistan   \n",
      "6929  40.0    6.0              57.0       1  False         7.0        Uganda   \n",
      "\n",
      "     revenue  \n",
      "6252       0  \n",
      "4684       2  \n",
      "1731       1  \n",
      "4742       1  \n",
      "4521       1  \n",
      "...      ...  \n",
      "6412       2  \n",
      "8285       0  \n",
      "7853       1  \n",
      "1095       0  \n",
      "6929       2  \n",
      "\n",
      "[2000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "customers_copy[\"revenue\"]=pd.qcut(customers_copy.revenue,3,labels=[\"0\",\"1\",\n",
    "   \"2\"])\n",
    "test_copy[\"revenue\"]=pd.qcut(test_copy.revenue,3,labels=[\"0\",\"1\",\n",
    "   \"2\"])\n",
    "\n",
    "print(customers_copy)\n",
    "print(test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c5a5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>pages</th>\n",
       "      <th>first_item_prize</th>\n",
       "      <th>gender</th>\n",
       "      <th>ReBuy</th>\n",
       "      <th>News_click</th>\n",
       "      <th>country</th>\n",
       "      <th>revenue</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp_inhab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>38700000</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>38700000</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>1</td>\n",
       "      <td>38700000</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>38700000</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>0</td>\n",
       "      <td>38700000</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  pages  first_item_prize  gender  ReBuy  News_click  country revenue  \\\n",
       "0  54.0    3.0              15.5       0  False         3.0  Algeria       0   \n",
       "1  39.0    2.0              10.0       0   True         4.0  Algeria       0   \n",
       "2  30.0    1.0              44.0       0  False         4.0  Algeria       1   \n",
       "3  36.0    6.0              44.0       1  False         3.0  Algeria       0   \n",
       "4  32.0    3.0              28.0       1  False         3.0  Algeria       0   \n",
       "\n",
       "   population  gdp_inhab  \n",
       "0    38700000       7268  \n",
       "1    38700000       7268  \n",
       "2    38700000       7268  \n",
       "3    38700000       7268  \n",
       "4    38700000       7268  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#Création de la fonction pour merge\n",
    "def add_extra_features(data, add_PIB = True):\n",
    "    #Merge CountryPopulation à data par rapport à la variable 'country'\n",
    "    data = data.merge(country_population, on = 'country')\n",
    "    if(add_PIB):\n",
    "        #Merge CountryGDP à data par rapport à la variable 'country'\n",
    "        data = data.merge(country_PIB, on = 'country')\n",
    "        return data\n",
    "    else:\n",
    "        #Ne pas merge CountryGDP\n",
    "        return data\n",
    "\n",
    "#Utilisation de la fonction pour merge\n",
    "#Scénario 1 (dataset d'entraînement)\n",
    "customers_extra_noPIB = add_extra_features(customers_copy, False)\n",
    "#Scénario 2 (dataset d'entraînement)\n",
    "customers_extra_PIB = add_extra_features(customers_copy)\n",
    "\n",
    "#Scénario 1 (dataset de test)\n",
    "testCustomers_extra_noPIB = add_extra_features(test_copy, False)\n",
    "#Scénario 2 (dataset de test)\n",
    "testCustomers_extra_PIB = add_extra_features(test_copy)\n",
    "\n",
    "#Vérification de nos merge\n",
    "customers_extra_noPIB.head()\n",
    "customers_extra_PIB.head()\n",
    "testCustomers_extra_noPIB.head()\n",
    "testCustomers_extra_PIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f4b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000000\n",
      "2    0.000125\n",
      "1   -0.000125\n",
      "Name: revenue, dtype: float64\n",
      "0    0.000000\n",
      "2   -0.000125\n",
      "1    0.000125\n",
      "Name: revenue, dtype: float64\n",
      "0    0.0\n",
      "2    0.0\n",
      "1    0.0\n",
      "Name: revenue, dtype: float64\n",
      "0    0.000000\n",
      "2    0.000125\n",
      "1   -0.000125\n",
      "Name: revenue, dtype: float64\n",
      "0    0.000000\n",
      "2   -0.000125\n",
      "1    0.000125\n",
      "Name: revenue, dtype: float64\n",
      "0    0.0\n",
      "2    0.0\n",
      "1    0.0\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#Création d'un échantillon de 2000 observations pour le scénario 1\n",
    "echantillon_customers_noPIB2000 = resample(customers_extra_noPIB, n_samples=2000, replace=False,\n",
    "                                          stratify=customers_extra_noPIB['revenue'],\n",
    "                                          random_state=5)\n",
    "echantillon_customers_noPIB2000.name = \"echantillon_customers_noPIB2000\"\n",
    "\n",
    "\n",
    "#Création d'un échantillon de 2000 observations pour le scénario 2\n",
    "echantillon_customers_PIB2000 = resample(customers_extra_PIB, n_samples=2000, replace=False,\n",
    "                                          stratify=customers_extra_PIB['revenue'],\n",
    "                                          random_state=5)\n",
    "echantillon_customers_PIB2000.name = \"echantillon_customers_PIB2000\"\n",
    "\n",
    "#Création d'un échantillon de 4000 observations pour le scénario 1\n",
    "echantillon_customers_noPIB4000 = resample(customers_extra_noPIB, n_samples=4000, replace=False,\n",
    "                                          stratify=customers_extra_noPIB['revenue'],\n",
    "                                          random_state=5)\n",
    "echantillon_customers_noPIB4000.name = \"echantillon_customers_noPIB4000\"\n",
    "\n",
    "#Création d'un échantillon de 4000 observations pour le scénario 2\n",
    "echantillon_customers_PIB4000 = resample(customers_extra_PIB, n_samples=4000, replace=False,\n",
    "                                          stratify=customers_extra_PIB['revenue'],\n",
    "                                          random_state=5)\n",
    "echantillon_customers_PIB4000.name = \"echantillon_customers_PIB4000\"\n",
    "\n",
    "#Création d'un échantillon de 8000 observations pour le scénario 1\n",
    "echantillon_customers_noPIB8000 = resample(customers_extra_noPIB, n_samples=8000, replace=False,\n",
    "                                          stratify=customers_extra_noPIB['revenue'],\n",
    "                                          random_state=5)\n",
    "echantillon_customers_noPIB8000.name = \"echantillon_customers_noPIB8000\"\n",
    "\n",
    "#Création d'un échantillon de 8000 observations pour le scénario 2\n",
    "echantillon_customers_PIB8000 = resample(customers_extra_PIB, n_samples=8000, replace=False,\n",
    "                                          stratify=customers_extra_PIB['revenue'],\n",
    "                                          random_state=5)\n",
    "echantillon_customers_PIB8000.name = \"echantillon_customers_PIB8000\"\n",
    "\n",
    "#Vérification des échantillons si les fréquences sont similaires pour le scénario 1\n",
    "print((echantillon_customers_noPIB2000['revenue'].value_counts()/len(echantillon_customers_noPIB2000)) - customers_extra_noPIB['revenue'].value_counts()/len(customers_extra_noPIB))\n",
    "print((echantillon_customers_noPIB4000['revenue'].value_counts()/len(echantillon_customers_noPIB4000)) - customers_extra_noPIB['revenue'].value_counts()/len(customers_extra_noPIB))\n",
    "print((echantillon_customers_noPIB8000['revenue'].value_counts()/len(echantillon_customers_noPIB8000)) - customers_extra_noPIB['revenue'].value_counts()/len(customers_extra_noPIB))\n",
    "\n",
    "#Vérification des échantillons si les fréquences sont similaires pour le scénario 2\n",
    "print((echantillon_customers_PIB2000['revenue'].value_counts()/len(echantillon_customers_PIB2000)) - customers_extra_PIB['revenue'].value_counts()/len(customers_extra_PIB))\n",
    "print((echantillon_customers_PIB4000['revenue'].value_counts()/len(echantillon_customers_PIB4000)) - customers_extra_PIB['revenue'].value_counts()/len(customers_extra_PIB))\n",
    "print((echantillon_customers_PIB8000['revenue'].value_counts()/len(echantillon_customers_PIB8000)) - customers_extra_PIB['revenue'].value_counts()/len(customers_extra_PIB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d748437c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.3360\n",
       "2    0.3325\n",
       "1    0.3315\n",
       "Name: revenue, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echantillon_customers_noPIB2000['revenue'].value_counts()/len(echantillon_customers_noPIB2000)\n",
    "#customers_extra_noPIB['revenue'].value_counts()/len(customers_extra_noPIB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4188a",
   "metadata": {},
   "source": [
    "## Entraîner une forêt d'arbres crée aléatoirement\n",
    "\n",
    "Pour cela nous allons créer la fonction **forestdecision()** qui prend en paramètre les données de test (X_test, y_test). Pour ensuite entraîner le classifier **DecisionTreeClassifier** sur des échantillons aléatoires de même taille. Pour cela on utilisera la validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6545ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forestdecision(X_data, y_data, classifier, k):\n",
    "\n",
    "    sk_folds = StratifiedKFold(n_splits = k)\n",
    "\n",
    "    scores = cross_val_score(classifier, X_data, y_data, cv = sk_folds)\n",
    "\n",
    "    print(\"Cross Validation Scores: \", scores)\n",
    "    print(\"Best CV Score: \", scores.max())\n",
    "    print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5756322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores:  [0.4375 0.3125 0.5625 0.5    0.5625 0.5625 0.875  0.6875 0.5    0.375\n",
      " 0.5625 0.625  0.75   0.375  0.5625 0.625  0.5    0.375  0.5    0.875\n",
      " 0.625  0.5625 0.75   0.625  0.5    0.5625 0.625  0.5    0.4375 0.375\n",
      " 0.625  0.5    0.6875 0.6875 0.75   0.6875 0.5625 0.5625 0.8125 0.6875\n",
      " 0.4375 0.5625 0.75   0.5    0.375  0.5625 0.5    0.5625 0.625  0.75\n",
      " 0.4375 0.5    0.6875 0.3125 0.4375 0.5    0.6875 0.4375 0.5625 0.75\n",
      " 0.5625 0.625  0.625  0.5625 0.5625 0.625  0.5    0.3125 0.5    0.5625\n",
      " 0.5    0.6875 0.5    0.625  0.4375 0.5625 0.625  0.625  0.5    0.3125\n",
      " 0.75   0.625  0.625  0.5    0.5    0.5625 0.625  0.4375 0.5    0.625\n",
      " 0.625  0.8125 0.4375 0.375  0.6875 0.5    0.5    0.75   0.75   0.625 ]\n",
      "Best CV Score:  0.875\n",
      "Number of CV Scores used in Average:  100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import math\n",
    "\n",
    "X_PIB = echantillon_customers_PIB2000.drop([\"revenue\", \"country\"],axis=1) \n",
    "y_PIB = echantillon_customers_PIB2000.revenue\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_PIB, y_PIB, test_size=0.2, random_state=1)\n",
    "\n",
    "#instantiate model with best hyperparameters\n",
    "clf = DecisionTreeClassifier(splitter = \"random\", max_features = math.log(2,2))\n",
    "\n",
    "forestdecision(X_train, y_train, clf, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "967d74f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.68       673\n",
      "           1       0.43      0.41      0.42       660\n",
      "           2       0.62      0.64      0.63       667\n",
      "\n",
      "    accuracy                           0.58      2000\n",
      "   macro avg       0.57      0.58      0.58      2000\n",
      "weighted avg       0.57      0.58      0.58      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_Test = testCustomers_extra_PIB.drop([\"revenue\", \"country\"],axis=1)\n",
    "y_Test = testCustomers_extra_PIB.revenue\n",
    "\n",
    "#Utilisation des nouveaux paramètres de DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(splitter = \"random\", max_features = math.log(2,2))\n",
    "clf.fit(X_train, y_train)\n",
    "forest_prediction = clf.predict(X_Test) \n",
    "\n",
    "#X_Test.info()\n",
    "print(sklearn.metrics.classification_report(y_Test, forest_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce918847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour un nombre de passes k = 3 : \n",
      "Cross Validation Scores:  [0.5625   0.421875 0.546875 0.46875  0.546875 0.484375 0.59375  0.625\n",
      " 0.671875 0.625    0.609375 0.53125  0.640625 0.609375 0.546875 0.5625\n",
      " 0.484375 0.5625   0.5625   0.5625   0.5625   0.5625   0.609375 0.578125\n",
      " 0.59375  0.5625   0.609375 0.625    0.515625 0.640625 0.609375 0.609375\n",
      " 0.609375 0.53125  0.578125 0.6875   0.5      0.53125  0.65625  0.671875\n",
      " 0.59375  0.578125 0.625    0.53125  0.671875 0.578125 0.609375 0.515625\n",
      " 0.625    0.546875 0.578125 0.75     0.515625 0.5625   0.578125 0.578125\n",
      " 0.53125  0.609375 0.46875  0.65625  0.53125  0.53125  0.671875 0.65625\n",
      " 0.578125 0.640625 0.65625  0.5625   0.46875  0.609375 0.671875 0.546875\n",
      " 0.59375  0.625    0.5      0.671875 0.578125 0.546875 0.671875 0.671875\n",
      " 0.703125 0.65625  0.65625  0.515625 0.6875   0.609375 0.609375 0.578125\n",
      " 0.640625 0.609375 0.484375 0.578125 0.75     0.65625  0.609375 0.578125\n",
      " 0.59375  0.625    0.546875 0.609375]\n",
      "Best CV Score:  0.75\n",
      "Number of CV Scores used in Average:  100\n",
      "-------------------------------------------------\n",
      "Pour un nombre de passes k = 10 : \n",
      "Cross Validation Scores:  [0.625    0.671875 0.53125  0.625    0.546875 0.53125  0.703125 0.640625\n",
      " 0.59375  0.609375 0.59375  0.5      0.625    0.609375 0.5      0.484375\n",
      " 0.53125  0.59375  0.59375  0.4375   0.640625 0.5625   0.59375  0.640625\n",
      " 0.578125 0.546875 0.609375 0.5      0.546875 0.609375 0.546875 0.5625\n",
      " 0.546875 0.578125 0.625    0.6875   0.5      0.59375  0.6875   0.6875\n",
      " 0.640625 0.5625   0.6875   0.671875 0.65625  0.75     0.578125 0.5\n",
      " 0.609375 0.59375  0.546875 0.734375 0.53125  0.515625 0.578125 0.6875\n",
      " 0.578125 0.546875 0.59375  0.59375  0.59375  0.546875 0.640625 0.609375\n",
      " 0.609375 0.671875 0.65625  0.65625  0.5      0.578125 0.75     0.546875\n",
      " 0.515625 0.609375 0.59375  0.671875 0.5625   0.59375  0.6875   0.65625\n",
      " 0.546875 0.578125 0.671875 0.59375  0.5625   0.578125 0.609375 0.625\n",
      " 0.59375  0.5625   0.53125  0.53125  0.765625 0.609375 0.578125 0.640625\n",
      " 0.625    0.53125  0.609375 0.6875  ]\n",
      "Best CV Score:  0.765625\n",
      "Number of CV Scores used in Average:  100\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params_echantillon = ['echantillon_customers_noPIB2000','echantillon_customers_noPIB4000', 'echantillon_customers_noPIB8000', 'echantillon_customers_PIB2000', 'echantillon_customers_PIB4000', 'echantillon_customers_PIB8000']\n",
    "\n",
    "def informations_resultats(echantillon):\n",
    "    X_PIB = echantillon.drop([\"revenue\", \"country\"],axis=1) \n",
    "    y_PIB = echantillon.revenue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_PIB, y_PIB, test_size=0.2, random_state=1)\n",
    "    \n",
    "    params = {'max_depth': list(range(2,20)), 'min_samples_split': [10,15,20]}\n",
    "\n",
    "    for k in range(2):\n",
    "        if k == 0:\n",
    "            print(\"Pour un nombre de passes k = 3 : \")\n",
    "            clf = DecisionTreeClassifier(splitter = \"random\", max_features = math.log(2,2))\n",
    "\n",
    "            forestdecision(X_train, y_train, clf, 100)\n",
    "\n",
    "        else:\n",
    "            print(\"-------------------------------------------------\")\n",
    "            print(\"Pour un nombre de passes k = 10 : \")\n",
    "            clf = DecisionTreeClassifier(splitter = \"random\", max_features = math.log(2,2))\n",
    "\n",
    "            forestdecision(X_train, y_train, clf, 100)\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "informations_resultats(echantillon_customers_PIB8000) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafd440",
   "metadata": {},
   "source": [
    "## Meilleur classeur pour discriminer les 3 revenus\n",
    "\n",
    "Le classeur aléatoire est plus fiable que le classeur multi-classe donc on peut dire que le classeur aléatoire est plus apte à discriminer les 3 revenus.\n",
    "\n",
    "## Classeur binaire VS Classeur multi-classes VS Classeur aléatoire\n",
    "\n",
    "On voit directement que le classeur aléatoire a des meilleurs score que le classeur multi-classe. Cependant entre le classeur bianire et le classeur aléatoire les scores se ressemble avec une fiabilité légérement plus élevé pour le classeur aléatoire."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
